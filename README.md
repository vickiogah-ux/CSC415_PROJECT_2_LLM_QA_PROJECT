# LLM Question-and-Answering System

A comprehensive Question-and-Answering system built with Python that connects to Large Language Model (LLM) APIs. This project includes both a powerful CLI application and a beautiful web-based GUI.

## ğŸŒŸ Features

### CLI Application (LLM_QA_CLI.py)
- âœ… Natural language question input
- âœ… Advanced NLP preprocessing:
  - Lowercasing
  - Tokenization
  - Punctuation removal
  - Extra whitespace handling
- âœ… Support for multiple LLM providers:
  - Groq (default, free and fast)
  - OpenAI
  - Cohere
  - Google Gemini
- âœ… Interactive command-line interface
- âœ… Display of processed questions and tokens

### Web GUI Application (Flask)
- âœ… Modern, responsive web interface
- âœ… Real-time question processing
- âœ… Beautiful result visualization
- âœ… Token display with animated badges
- âœ… Copy-to-clipboard functionality
- âœ… Error handling with user feedback
- âœ… Health check endpoint
- âœ… Mobile-responsive design

## ğŸ“‹ Project Structure

```
LLM_QA_Project/
â”œâ”€â”€ LLM_QA_CLI.py              # Command-line interface
â”œâ”€â”€ app.py                      # Flask web application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Web GUI HTML template
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css             # Web GUI styling
â””â”€â”€ LLM_QA_hosted_webGUI_link.txt  # Hosted URL (after deployment)
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip (Python package manager)
- An API key from one of the supported LLM providers

### Installation

1. **Clone the repository** (or download the project folder)
   ```bash
   cd LLM_QA_Project
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   # Copy the example file
   cp .env.example .env

   # Edit .env and add your API key
   # For Groq: Get a free key from https://console.groq.com/keys
   ```

   Example `.env` file:
   ```
   GROQ_API_KEY=your_api_key_here
   LLM_PROVIDER=groq
   FLASK_DEBUG=True
   FLASK_PORT=5000
   ```

### Running the Application

#### Option 1: CLI Application
```bash
python LLM_QA_CLI.py
```

Interactive usage:
```
ğŸ“ Enter your question (or 'quit' to exit): What is machine learning?

â³ Processing your question...

ğŸ“Œ ORIGINAL QUESTION:
   What is machine learning?

ğŸ”¤ PROCESSED QUESTION:
   what is machine learning

ğŸ”¤ TOKENIZED WORDS:
   what, is, machine, learning

ğŸ’¡ ANSWER:
   [LLM response here...]
```

#### Option 2: Web GUI (Flask)
```bash
python app.py
```

Then open your browser and navigate to:
```
http://127.0.0.1:5000
```

## ğŸ”§ Configuration

### Supported LLM Providers

#### Groq (Recommended - Free & Fast)
- **Website**: https://console.groq.com/
- **Model**: Mixtral 8x7B
- **Speed**: Very fast
- **Cost**: Free tier available
- **Setup**:
  ```
  LLM_PROVIDER=groq
  GROQ_API_KEY=your_key_here
  ```

#### OpenAI
- **Website**: https://platform.openai.com/
- **Model**: GPT-3.5 Turbo
- **Setup**:
  ```
  LLM_PROVIDER=openai
  OPENAI_API_KEY=your_key_here
  ```

#### Cohere
- **Website**: https://cohere.com/
- **Model**: Command R
- **Setup**:
  ```
  LLM_PROVIDER=cohere
  COHERE_API_KEY=your_key_here
  ```

#### Google Gemini
- **Website**: https://makersuite.google.com/
- **Model**: Gemini Pro
- **Setup**:
  ```
  LLM_PROVIDER=gemini
  GEMINI_API_KEY=your_key_here
  ```

## ğŸ“š API Endpoints (Flask)

### POST /api/ask
Submit a question and get a response.

**Request:**
```json
{
  "question": "What is artificial intelligence?"
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "original_question": "What is artificial intelligence?",
    "processed_question": "what is artificial intelligence",
    "tokens": ["what", "is", "artificial", "intelligence"],
    "token_count": 4,
    "answer": "Artificial intelligence (AI) is..."
  }
}
```

### GET /api/health
Check API health status.

**Response:**
```json
{
  "status": "healthy",
  "provider": "groq"
}
```

## ğŸŒ Deployment

### Deploy to Streamlit Cloud

1. **Push to GitHub**:
   - Create a GitHub repository
   - Push your project files

2. **Create Streamlit version** (Optional: For Streamlit Cloud compatibility):
   - Streamlit Cloud works best with `streamlit_app.py` or `app.py` using Streamlit

3. **Deploy on Streamlit Cloud**:
   - Go to https://streamlit.io/cloud
   - Connect your GitHub repository
   - Select the main file to run
   - Add secrets for API keys

### Deploy to Render.com

1. **Push to GitHub**
2. **Create Render account** at https://render.com
3. **Create New Web Service**:
   - Connect GitHub repository
   - Set build command: `pip install -r requirements.txt`
   - Set start command: `gunicorn app:app`
4. **Add environment variables** for API keys
5. **Deploy**

### Deploy to PythonAnywhere

1. **Upload project files**
2. **Set up virtual environment**
3. **Configure WSGI file**
4. **Add environment variables**
5. **Reload web app**

## ğŸ§ª Testing

### Test CLI
```bash
python LLM_QA_CLI.py
# Type: "What is Python programming?"
# Press Ctrl+C to exit
```

### Test Web GUI
```bash
# Terminal 1: Start Flask app
python app.py

# Terminal 2: Test API endpoint
curl -X POST http://localhost:5000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Hello, how are you?"}'
```

## ğŸ¯ NLP Preprocessing Details

The system applies the following preprocessing steps:

1. **Lowercasing**: Converts all text to lowercase for consistency
   - Input: "What IS Machine Learning?"
   - Output: "what is machine learning?"

2. **Tokenization**: Splits text into individual words/tokens
   - Input: "what is machine learning?"
   - Output: ["what", "is", "machine", "learning"]

3. **Punctuation Removal**: Removes special characters
   - Input: "What is AI?"
   - Output: "what is ai"

4. **Whitespace Normalization**: Removes extra spaces
   - Input: "what  is   ai"
   - Output: "what is ai"

## ğŸ“¦ Dependencies

- **Flask 3.0.0**: Web framework
- **python-dotenv 1.0.0**: Environment variable management
- **groq 0.4.2**: Groq API client
- **openai 1.3.0**: OpenAI API client
- **cohere 4.47**: Cohere API client
- **google-generativeai 0.3.0**: Google Gemini client
- **nltk 3.8.1**: Natural Language Processing Toolkit
- **requests 2.31.0**: HTTP library
- **gunicorn 21.2.0**: WSGI HTTP Server

## âš ï¸ Important Notes

1. **API Keys**: Keep your API keys secret. Never commit `.env` files to version control.
2. **Rate Limits**: Be aware of rate limits for your chosen API provider.
3. **Costs**: Some APIs may have usage costs. Check provider pricing.
4. **NLTK Data**: The system automatically downloads required NLTK data on first use.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:
- Report bugs
- Suggest improvements
- Submit pull requests

## ğŸ“„ License

This project is created for educational purposes.

## ğŸ“ Credits

Created for CSC 415 - Project 2 at Covenant University

**Student Information:**
- **Name**: [Your Name]
- **Matric Number**: [Your Matric Number]
- **Institution**: Covenant University
- **Department**: Computer Science
- **Level**: 400

## ğŸ“ Support

For issues or questions:
1. Check the README thoroughly
2. Review error messages
3. Check API provider documentation
4. Test with different questions

## ğŸ”— Useful Links

- [Groq Console](https://console.groq.com/)
- [OpenAI API](https://platform.openai.com/)
- [Cohere Dashboard](https://cohere.com/)
- [Google Gemini](https://makersuite.google.com/)
- [Flask Documentation](https://flask.palletsprojects.com/)
- [NLTK Documentation](https://www.nltk.org/)

---

**Last Updated**: November 2025
